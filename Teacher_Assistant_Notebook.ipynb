{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL82FO7outUU"
      },
      "outputs": [],
      "source": [
        "pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5xwZ17Tuw7f"
      },
      "outputs": [],
      "source": [
        "pip install nni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFSE0lDdu8gY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nni\n",
        "import copy\n",
        "import torch\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from data_loader import get_cifar\n",
        "from model_factory import create_cnn_model, is_resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olHIk-Kh0z9L"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byq5QVmIvI_O"
      },
      "outputs": [],
      "source": [
        "def str2bool(v):\n",
        "\tif v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "\t\treturn True\n",
        "\telse:\n",
        "\t\treturn False\n",
        "\n",
        "\n",
        "def parse_arguments():\n",
        "\tparser = argparse.ArgumentParser(description='TA Knowledge Distillation Code')\n",
        "\n",
        "\tparser.add_argument('--epochs', default=100, type=int,  help='number of total epochs to run')\n",
        "\tparser.add_argument('--dataset', default='cifar10', type=str, help='dataset. can be either cifar10 or cifar100')\n",
        "\tparser.add_argument('--batch-size', default=128, type=int, help='batch_size')\n",
        "\tparser.add_argument('--learning-rate', default=0.1, type=float, help='initial learning rate')\n",
        "\tparser.add_argument('--momentum', default=0.9, type=float,  help='SGD momentum')\n",
        "\tparser.add_argument('--weight-decay', default=1e-4, type=float, help='SGD weight decay (default: 1e-4)')\n",
        "\tparser.add_argument('--teacher', default='', type=str, help='teacher student name')\n",
        "\tparser.add_argument('--student', '--model', default='resnet8', type=str, help='teacher student name')\n",
        "\tparser.add_argument('--teacher-checkpoint', default='', type=str, help='optinal pretrained checkpoint for teacher')\n",
        "\tparser.add_argument('--cuda', default=False, type=str2bool, help='whether or not use cuda(train on GPU)')\n",
        "\tparser.add_argument('--dataset-dir', default='./data', type=str,  help='dataset directory')\n",
        "  # parser.add_argument('-f')\n",
        "\targs = parser.parse_args()\n",
        "\treturn args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oKzvzrzw_a9"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(model, checkpoint_path):\n",
        "\t\"\"\"\n",
        "\tLoads weights from checkpoint\n",
        "\t:param model: a pytorch nn student\n",
        "\t:param str checkpoint_path: address/path of a file\n",
        "\t:return: pytorch nn student with weights loaded from checkpoint\n",
        "\t\"\"\"\n",
        "\tmodel_ckp = torch.load(checkpoint_path)\n",
        "\tmodel.load_state_dict(model_ckp['model_state_dict'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDD2uC-0xK5w"
      },
      "outputs": [],
      "source": [
        "class TrainManager(object):\n",
        "\tdef __init__(self, student, teacher=None, train_loader=None, test_loader=None, train_config={}):\n",
        "\t\tself.student = student\n",
        "\t\tself.teacher = teacher\n",
        "\t\tself.have_teacher = bool(self.teacher)\n",
        "\t\tself.device = train_config['device']\n",
        "\t\tself.name = train_config['name']\n",
        "\t\tself.optimizer = optim.SGD(self.student.parameters(),\n",
        "\t\t\t\t\t\t\t\t   lr=train_config['learning_rate'],\n",
        "\t\t\t\t\t\t\t\t   momentum=train_config['momentum'],\n",
        "\t\t\t\t\t\t\t\t   weight_decay=train_config['weight_decay'])\n",
        "\t\tif self.have_teacher:\n",
        "\t\t\tself.teacher.eval()\n",
        "\t\t\tself.teacher.train(mode=False)\n",
        "\n",
        "\t\tself.train_loader = train_loader\n",
        "\t\tself.test_loader = test_loader\n",
        "\t\tself.config = train_config\n",
        "\n",
        "\tdef train(self):\n",
        "\t\tlambda_ = self.config['lambda_student']\n",
        "\t\tT = self.config['T_student']\n",
        "\t\tepochs = self.config['epochs']\n",
        "\t\ttrial_id = self.config['trial_id']\n",
        "\n",
        "\t\tmax_val_acc = 0\n",
        "\t\titeration = 0\n",
        "\t\tbest_acc = 0\n",
        "\t\tcriterion = nn.CrossEntropyLoss()\n",
        "\t\tfor epoch in range(epochs):\n",
        "\t\t\tself.student.train()\n",
        "\t\t\tself.adjust_learning_rate(self.optimizer, epoch)\n",
        "\t\t\tloss = 0\n",
        "\t\t\tfor batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "\t\t\t\titeration += 1\n",
        "\t\t\t\tdata = data.to(self.device)\n",
        "\t\t\t\ttarget = target.to(self.device)\n",
        "\t\t\t\tself.optimizer.zero_grad()\n",
        "\t\t\t\toutput = self.student(data)\n",
        "\t\t\t\t# Standard Learning Loss ( Classification Loss)\n",
        "\t\t\t\tloss_SL = criterion(output, target)\n",
        "\t\t\t\tloss = loss_SL\n",
        "\n",
        "\t\t\t\tif self.have_teacher:\n",
        "\t\t\t\t\tteacher_outputs = self.teacher(data)\n",
        "\t\t\t\t\t# Knowledge Distillation Loss\n",
        "\t\t\t\t\tloss_KD = nn.KLDivLoss()(F.log_softmax(output / T, dim=1),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t  F.softmax(teacher_outputs / T, dim=1))\n",
        "\t\t\t\t\tloss = (1 - lambda_) * loss_SL + lambda_ * T * T * loss_KD\n",
        "\n",
        "\t\t\t\tloss.backward()\n",
        "\t\t\t\tself.optimizer.step()\n",
        "\n",
        "\t\t\tprint(\"epoch {}/{}\".format(epoch, epochs))\n",
        "\t\t\tval_acc = self.validate(step=epoch)\n",
        "\t\t\tif val_acc > best_acc:\n",
        "\t\t\t\tbest_acc = val_acc\n",
        "\t\t\t\tself.save(epoch, name='{}_{}_best.pth.tar'.format(self.name, trial_id))\n",
        "\n",
        "\t\treturn best_acc\n",
        "\n",
        "\tdef validate(self, step=0):\n",
        "\t\tself.student.eval()\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tcorrect = 0\n",
        "\t\t\ttotal = 0\n",
        "\t\t\tacc = 0\n",
        "\t\t\tfor images, labels in self.test_loader:\n",
        "\t\t\t\timages = images.to(self.device)\n",
        "\t\t\t\tlabels = labels.to(self.device)\n",
        "\t\t\t\toutputs = self.student(images)\n",
        "\t\t\t\t_, predicted = torch.max(outputs.data, 1)\n",
        "\t\t\t\ttotal += labels.size(0)\n",
        "\t\t\t\tcorrect += (predicted == labels).sum().item()\n",
        "\t\t\t# self.accuracy_history.append(acc)\n",
        "\t\t\tacc = 100 * correct / total\n",
        "\n",
        "\t\t\tprint('{{\"metric\": \"{}_val_accuracy\", \"value\": {}}}'.format(self.name, acc))\n",
        "\t\t\treturn acc\n",
        "\n",
        "\tdef save(self, epoch, name=None):\n",
        "\t\ttrial_id = self.config['trial_id']\n",
        "\t\tif name is None:\n",
        "\t\t\ttorch.save({\n",
        "\t\t\t\t'epoch': epoch,\n",
        "\t\t\t\t'model_state_dict': self.student.state_dict(),\n",
        "\t\t\t\t'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "\t\t\t}, '{}_{}_epoch{}.pth.tar'.format(self.name, trial_id, epoch))\n",
        "\t\telse:\n",
        "\t\t\ttorch.save({\n",
        "\t\t\t\t'model_state_dict': self.student.state_dict(),\n",
        "\t\t\t\t'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "\t\t\t\t'epoch': epoch,\n",
        "\t\t\t}, name)\n",
        "\n",
        "\tdef adjust_learning_rate(self, optimizer, epoch):\n",
        "\t\tepochs = self.config['epochs']\n",
        "\t\tmodels_are_plane = self.config['is_plane']\n",
        "\n",
        "\t\t# depending on dataset\n",
        "\t\tif models_are_plane:\n",
        "\t\t\tlr = 0.01\n",
        "\t\telse:\n",
        "\t\t\tif epoch < int(epoch/2.0):\n",
        "\t\t\t\tlr = 0.1\n",
        "\t\t\telif epoch < int(epochs*3/4.0):\n",
        "\t\t\t\tlr = 0.1 * 0.1\n",
        "\t\t\telse:\n",
        "\t\t\t\tlr = 0.1 * 0.01\n",
        "\n",
        "\t\t# update optimizer's learning rate\n",
        "\t\tfor param_group in optimizer.param_groups:\n",
        "\t\t\tparam_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUVTO7aGxiEW",
        "outputId": "e9af7140-6f33-4817-8c2e-6196ac3044f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(epochs=200, dataset='cifar100', batch_size=128, learning_rate=0.1, momentum=0.9, weight_decay=0.0001, teacher='', student='resnet8', teacher_checkpoint='', cuda=False, dataset_dir='./data')\n",
            "---------- Training Student -------\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:02<00:00, 73782225.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "epoch 0/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 8.93}\n",
            "epoch 1/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 11.88}\n",
            "epoch 2/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 14.43}\n",
            "epoch 3/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 15.68}\n",
            "epoch 4/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 18.71}\n",
            "epoch 5/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 21.73}\n",
            "epoch 6/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 24.58}\n",
            "epoch 7/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 25.47}\n",
            "epoch 8/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 27.77}\n",
            "epoch 9/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 30.12}\n",
            "epoch 10/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 31.55}\n",
            "epoch 11/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 31.99}\n",
            "epoch 12/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 32.07}\n",
            "epoch 13/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 34.0}\n",
            "epoch 14/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 34.62}\n",
            "epoch 15/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 32.86}\n",
            "epoch 16/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 37.08}\n",
            "epoch 17/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 38.62}\n",
            "epoch 18/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 40.21}\n",
            "epoch 19/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 40.22}\n",
            "epoch 20/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 40.31}\n",
            "epoch 21/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 40.78}\n",
            "epoch 22/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 40.7}\n",
            "epoch 23/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 42.48}\n",
            "epoch 24/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 40.46}\n",
            "epoch 25/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 43.09}\n",
            "epoch 26/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 42.36}\n",
            "epoch 27/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 40.83}\n",
            "epoch 28/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 44.63}\n",
            "epoch 29/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 42.95}\n",
            "epoch 30/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 44.11}\n",
            "epoch 31/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 42.67}\n",
            "epoch 32/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 43.6}\n",
            "epoch 33/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 41.77}\n",
            "epoch 34/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 43.81}\n",
            "epoch 35/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 43.32}\n",
            "epoch 36/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 43.83}\n",
            "epoch 37/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 43.2}\n",
            "epoch 38/200\n",
            "{\"metric\": \"resnet8_val_accuracy\", \"value\": 42.06}\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\t# Parsing arguments and prepare settings for training\n",
        "\targs = parse_arguments()\n",
        "\tprint(args)\n",
        "\tconfig = nni.get_next_parameter()\n",
        "\t# torch.manual_seed(config['seed'])\n",
        "\t# torch.cuda.manual_seed(config['seed'])\n",
        "\ttrial_id = os.environ.get('NNI_TRIAL_JOB_ID')\n",
        "\tdataset = args.dataset\n",
        "\tnum_classes = 100 if dataset == 'cifar100' else 'cifar10'\n",
        "\tteacher_model = None\n",
        "\tstudent_model = create_cnn_model(args.student, dataset, use_cuda=args.cuda)\n",
        "  # student_model = create_cnn_model(args.student, dataset)\n",
        "\ttrain_config = {\n",
        "\t\t'epochs': args.epochs,\n",
        "\t\t'learning_rate': args.learning_rate,\n",
        "\t\t'momentum': args.momentum,\n",
        "\t\t'weight_decay': args.weight_decay,\n",
        "\t\t'device': 'cuda' if args.cuda else 'cpu',\n",
        "\t\t'is_plane': not is_resnet(args.student),\n",
        "\t\t'trial_id': trial_id,\n",
        "\t\t'T_student': config.get('T_student'),\n",
        "\t\t'lambda_student': config.get('lambda_student'),\n",
        "\t}\n",
        "\n",
        "\n",
        "\t# Train Teacher if provided a teacher, otherwise it's a normal training using only cross entropy loss\n",
        "\t# This is for training single models(NOKD in paper) for baselines models (or training the first teacher)\n",
        "\tif args.teacher:\n",
        "\t\tteacher_model = create_cnn_model(args.teacher, dataset, use_cuda=args.cuda)\n",
        "\t\tif args.teacher_checkpoint:\n",
        "\t\t\tprint(\"---------- Loading Teacher -------\")\n",
        "\t\t\tteacher_model = load_checkpoint(teacher_model, args.teacher_checkpoint)\n",
        "\t\telse:\n",
        "\t\t\tprint(\"---------- Training Teacher -------\")\n",
        "\t\t\ttrain_loader, test_loader = get_cifar(num_classes)\n",
        "\t\t\tteacher_train_config = copy.deepcopy(train_config)\n",
        "\t\t\tteacher_name = '{}_{}_best.pth.tar'.format(args.teacher, trial_id)\n",
        "\t\t\tteacher_train_config['name'] = args.teacher\n",
        "\t\t\tteacher_trainer = TrainManager(teacher_model, teacher=None, train_loader=train_loader, test_loader=test_loader, train_config=teacher_train_config)\n",
        "\t\t\tteacher_trainer.train()\n",
        "\t\t\tteacher_model = load_checkpoint(teacher_model, os.path.join('./', teacher_name))\n",
        "\n",
        "\t# Student training\n",
        "\tprint(\"---------- Training Student -------\")\n",
        "\tstudent_train_config = copy.deepcopy(train_config)\n",
        "\ttrain_loader, test_loader = get_cifar(num_classes)\n",
        "\tstudent_train_config['name'] = args.student\n",
        "\tstudent_trainer = TrainManager(student_model, teacher=teacher_model, train_loader=train_loader, test_loader=test_loader, train_config=student_train_config)\n",
        "\tbest_student_acc = student_trainer.train()\n",
        "\tnni.report_final_result(best_student_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKFRyRkaxwiw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}